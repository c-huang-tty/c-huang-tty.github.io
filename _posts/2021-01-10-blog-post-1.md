---
title: 'Statistics [10]: Evaluation of Point Estimation'
date: 2021-01-10
permalink: /posts/2021/01/10/properties-point-estimation/
tags:
  - Statistics
---

Properties of point estimation, mean squre error and minimum variance unbiased estimation.

---
## Properties of Point Estimation
### Consistency
Assume <img src="https://render.githubusercontent.com/render/math?math=\theta\in\Theta"> is an unknown parameter, <img src="https://render.githubusercontent.com/render/math?math=\hat{\theta}_n=\hat{\theta}_n(x_1,x_2,...,x_n)"> is an estimation obtained from <img src="https://render.githubusercontent.com/render/math?math=n"> samples. If for any <img src="https://render.githubusercontent.com/render/math?math=\varepsilon > 0">, there exists <img src="https://render.githubusercontent.com/render/math?math=n"> that satisfies <img src="https://render.githubusercontent.com/render/math?math={\displaystyle \lim_{n\to\infty}P(|\hat{\theta}-\theta| > \varepsilon) = 0}">. Then <img src="https://render.githubusercontent.com/render/math?math=\hat{\theta}"> is called a consistent estimation of <img src="https://render.githubusercontent.com/render/math?math=\theta">.

### Bias
Assume <img src="https://render.githubusercontent.com/render/math?math=\theta\in\Theta"> is an unknown parameter, <img src="https://render.githubusercontent.com/render/math?math=\hat{\theta}_n=\hat{\theta}_n(x_1,x_2,...,x_n)"> is an estimation obtained from <img src="https://render.githubusercontent.com/render/math?math=n"> samples. If for any <img src="https://render.githubusercontent.com/render/math?math=\theta\in\Theta"> there is <img src="https://render.githubusercontent.com/render/math?math=E(\hat{\theta})=\theta">. Then <img src="https://render.githubusercontent.com/render/math?math=\hat{\theta}"> is called an unbiased estimation of <img src="https://render.githubusercontent.com/render/math?math=\theta">.

### Efficiency
Assume <img src="https://render.githubusercontent.com/render/math?math=\hat{\theta}_1"> and <img src="https://render.githubusercontent.com/render/math?math=\hat{\theta}_2"> are two unbiased estimation. if for any <img src="https://render.githubusercontent.com/render/math?math=\theta\in\Theta"> there is <img src="https://render.githubusercontent.com/render/math?math=var(\hat{\theta}_1) \leq var(\hat{\theta}_2)">, and there exists at least one <img src="https://render.githubusercontent.com/render/math?math=\theta\in\Theta"> so that <img src="https://render.githubusercontent.com/render/math?math=var(\hat{\theta}_1) < var(\hat{\theta}_2)">. Then <img src="https://render.githubusercontent.com/render/math?math=var(\hat{\theta}_1)"> is more efficient than <img src="https://render.githubusercontent.com/render/math?math=var(\hat{\theta}_2)">.

---
### Example 1
Assume <img src="https://render.githubusercontent.com/render/math?math=X_1,X_2,...,X_n"> are samples from uniform distribution <img src="https://render.githubusercontent.com/render/math?math=U(0,\theta)">, the moment estimation is <img src="https://render.githubusercontent.com/render/math?math=\hat{\theta}=2\bar{X}"> and the maximum likelihood estimation is <img src="https://render.githubusercontent.com/render/math?math=\tilde{\theta}={\displaystyle \max_{1\leq k\leq n} X_k}">, consider the unbiasedness of <img src="https://render.githubusercontent.com/render/math?math=\hat{\theta}"> and <img src="https://render.githubusercontent.com/render/math?math=\tilde{\theta}">.

__Solution__. Fisrt, <img src="https://render.githubusercontent.com/render/math?math=E(\hat{\theta}) = E(2\bar{X}) = 2\times\dfrac{\theta}{2} \theta">, hence, <img src="https://render.githubusercontent.com/render/math?math=\hat{\theta}"> is an unbiased estimation.

As for <img src="https://render.githubusercontent.com/render/math?math=\tilde{\theta}">, when <img src="https://render.githubusercontent.com/render/math?math=0\leq y \leq \theta">, the distribution function of <img src="https://render.githubusercontent.com/render/math?math=y"> is 

<img src="https://render.githubusercontent.com/render/math?math=F_{\tilde{\theta}}(y) = P(\tilde{\theta}\leq y) = {\displaystyle P( \max_{1\leq k\leq n} X_k\leq y) = \prod_{k=1}^n P(X_k\leq y) = \left(\dfrac{y}{\theta}\right)^n}">

Then, the probability function would be

<img src="https://render.githubusercontent.com/render/math?math=f_{\tilde{\theta}}(y) = {\displaystyle \dfrac{n}{\theta^n}y^{n-1}}">

Hence, 

<img src="https://render.githubusercontent.com/render/math?math=E(\tilde{\theta}) = {\displaystyle \int_{-\infty}^\infty yf_{\tilde{\theta}}(y)dy = \int_{0}^yy\dfrac{n}{\theta^n}y^{n-1}dy} = \dfrac{n}{n%2B1}\theta">

Hence, <img src="https://render.githubusercontent.com/render/math?math=\tilde{\theta}"> is a biased estimation.

### Example 2
Assume <img src="https://render.githubusercontent.com/render/math?math=X_1,X_2,...,X_n"> are samples from uniform distribution <img src="https://render.githubusercontent.com/render/math?math=U(0,\theta)">, <img src="https://render.githubusercontent.com/render/math?math=\hat{\theta}_1=2\bar{X}"> and <img src="https://render.githubusercontent.com/render/math?math=\hat{\theta}_2={\displaystyle \dfrac{n%2B1}{n} \max_{1\leq k\leq n} X_k}">, compare their efficiency.

__Solution__. For <img src="https://render.githubusercontent.com/render/math?math=\hat{\theta}_1">, we have

<img src="https://render.githubusercontent.com/render/math?math=var(\hat{\theta}_1) = var(2\bar{X}) = 4var(\bar{X}) = 4\cdot\dfrac{\theta^2}{12n} = \dfrac{\theta^2}{3n}">

For <img src="https://render.githubusercontent.com/render/math?math=\hat{\theta}_2">, firstly, from example 1, we have

<img src="https://render.githubusercontent.com/render/math?math=E(\tilde{\theta}^2) = {\displaystyle \int_{0}^{\theta}y^2f_{\tilde{\theta}}(y)dy = \int_{0}^\theta y^2\dfrac{n}{\theta^n}y^{n-1}dy = \dfrac{n}{n%2B2}\theta^2}">

Then, we have

<img src="https://render.githubusercontent.com/render/math?math=var(\tilde{\theta}) = E(\tilde{\theta}^2) - E^2(\tilde{\theta}) = \dfrac{n}{n%2B2}\theta^2-\dfrac{n^2}{(n%2B 1)^2\theta^2} = \dfrac{n}{(n%2B1)^2(n%2B 2)}\theta^2">

Therefore, 

<img src="https://render.githubusercontent.com/render/math?math=var(\hat{\theta}_2) = \dfrac{(n%2B1)^2}{n^2}var(\tilde{\theta}) = \dfrac{1}{n(n%2B2)}\theta^2">
