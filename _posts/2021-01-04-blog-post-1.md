---
title: 'Statistics [04]: Some Common Continuous Distributions'
date: 2021-01-04
permalink: /posts/2021/01/04/some-common-continuous-distributions/
tags:
  - Statistics
---

This post will summarize some of the commonly used continuous distributions, including
- Uniform distribution
- Exponential distribution
- Weibull distribution
- Normal distribution
- <img src="https://render.githubusercontent.com/render/math?math=\chi^2"> distribution
- Student's t-distribution
- F-distribution
- Gamma distribution
- Beta Distribution

---
## Uniform Distribution
A uniform distribution, sometimes also known as a rectangular distribution, is a distribution that has constant probability. The probability density function and cumulative distribution function for a continuous uniform distribution on the interval <img src="https://render.githubusercontent.com/render/math?math=[a, b]"> are

<img src="/images/statistics/Uniform11.png" width="210"/>

<img src="/images/statistics/Uniform22.png" width="210"/>

![uniform](https://mathworld.wolfram.com/images/eps-svg/UniformDistribution_651.svg)

---
## Exponential Distribution
Poisson distribution describes the the number of events occurring over a period of time, where the non-overlapping intervals are independent. Exponential distribution describes the distribution of waiting times between successive changes.

Given a Possion distribution with parameter <img src="https://render.githubusercontent.com/render/math?math=\nu">, the distribution of waiting time would be

<img src="https://render.githubusercontent.com/render/math?math=D(x) = P(X\leq x) = 1 - P(X>x) = 1 - \dfrac{(\nu x)^0e^{-\nu x}}{0!} = 1 - e^{-\nu x}\ \ (x > 0)">

and the probability distribution function would be 

<img src="https://render.githubusercontent.com/render/math?math=P(x) = D\text{'}(x) = \nu e^{-\nu x}\ \ (x > 0) ">

![](https://mathworld.wolfram.com/images/eps-svg/ExponentialDistribution_1000.svg)

Like geometric distribution, exponential distribution is __memoryless__.

---
## Weibull Distribution
Expotential distribution can be seen as a special form of Weibull distribution, whose cumulative distribution function has the following form:

<img src="https://render.githubusercontent.com/render/math?math=D(x) =  1 - e^{-\left({x}\text{/}{\beta}\right)^\alpha}\ \ (x > 0)">

and the probability distribution function would be 

<img src="https://render.githubusercontent.com/render/math?math=P(x) = \alpha\beta^{-\alpha}x^{\alpha-1}e^{-\left({x}\text{/}{\beta}\right)^\alpha}\ \ (x > 0) ">

where <img src="https://render.githubusercontent.com/render/math?math=\beta"> is called __scale parameter__, and <img src="https://render.githubusercontent.com/render/math?math=\alpha"> is called __shape parameter__. Depending on its value, Weibull distribution can approximate various, even very different shapes. It is suitable for the characterization of time to failure as well as strength or load.

---
## Normal Distribution
Normal distribution is the most commonly used distribution in our life. It has the following probability density function.

<img src="https://render.githubusercontent.com/render/math?math=P(x) = \dfrac{1}{\sigma\sqrt{2\pi}}e^{-(x-\mu)^2\text{/}(2\sigma^2)} ">

where <img src="https://render.githubusercontent.com/render/math?math=\mu"> and <img src="https://render.githubusercontent.com/render/math?math=\sigma^2"> are mean and variance of <img src="https://render.githubusercontent.com/render/math?math=X"> respectively.

The so-called standard normal distribution is given by <img src="https://render.githubusercontent.com/render/math?math=\mu = 0"> and <img src="https://render.githubusercontent.com/render/math?math=\sigma^2 = 1"> in the general normal distribution. An arbitrary normal distribution can be converted to a standard normal distribution by changing variables to <img src="https://render.githubusercontent.com/render/math?math=z = (X-\mu)\text{/}\sigma">, yielding

<img src="https://render.githubusercontent.com/render/math?math=P(x)dx = \dfrac{1}{\sqrt{2\pi}}e^{-z^2\text{/}2}dz">

Based on the standard normal distribution, the cumulative distribution can then be found utilizing the lookup table.

![](https://mathworld.wolfram.com/images/eps-svg/NormalDistribution_651.svg)

---
## Chi-Squared Distribution
If <img src="https://render.githubusercontent.com/render/math?math=X_i"> have __normal independent__ distributions with mean 0 and variance 1, then

<img src="https://render.githubusercontent.com/render/math?math=Y = {\displaystyle \sum_{i=1}^nX_i^2 \sim \chi_n^2\text{/}\chi^2(n)}">

is a <img src="https://render.githubusercontent.com/render/math?math=\chi^2"> distribution with <img src="https://render.githubusercontent.com/render/math?math=n"> degrees of freedom.

More generally, if <img src="https://render.githubusercontent.com/render/math?math=\chi_i^2"> are independently distributed according to a <img src="https://render.githubusercontent.com/render/math?math=\chi^2"> distribution with <img src="https://render.githubusercontent.com/render/math?math=n_1, n_2, ..., n_k"> degrees of freedom, then

<img src="https://render.githubusercontent.com/render/math?math={\displaystyle \sum_{i=1}^{k}\chi_i^2}">

is distributed according to <img src="https://render.githubusercontent.com/render/math?math=\chi^2"> with <img src="https://render.githubusercontent.com/render/math?math=n = \sum_{i=1}^kn_i"> degrees of freedom. 

---
## Student's t-Distribution
Let <img src="https://render.githubusercontent.com/render/math?math=x_1, x_2, ..., x_n">  be independently and identically drawn from the distribution <img src="https://render.githubusercontent.com/render/math?math=N(\mu, \sigma^2)">. Let 

<img src="https://render.githubusercontent.com/render/math?math=\bar{X} = \dfrac{1}{n}{\displaystyle \sum_{i=1}^nX_i}">

be the sample mean and 

<img src="https://render.githubusercontent.com/render/math?math=S^2 = \dfrac{1}{n-1}{\displaystyle \sum_{i=1}^n(X_i-\bar{X})^2}">

be the sample variance. The the random variable 

<img src="https://render.githubusercontent.com/render/math?math=t = \dfrac{\bar{X} - \mu}{S\text{/}\sqrt{n}}">

has a Student's t-distribution with <img src="https://render.githubusercontent.com/render/math?math=n-1"> degrees of freedom.  

![](https://mathworld.wolfram.com/images/eps-svg/StudentsTDistribution_900.svg)

The only difference of Student's t-distribution with standard normal distribution is that the <img src="https://render.githubusercontent.com/render/math?math=\sigma"> in standard normal distribution is replaced with <img src="https://render.githubusercontent.com/render/math?math=S">. As <img src="https://render.githubusercontent.com/render/math?math=n"> increases, Student's t-distribution approaches the normal distribution.

---
## F-Distribution
F-distribution arises to test whether two observed samples has the same variance. Let <img src="https://render.githubusercontent.com/render/math?math=\chi_m^2"> and <img src="https://render.githubusercontent.com/render/math?math=\chi_n^2"> be independent <img src="https://render.githubusercontent.com/render/math?math=\chi^2"> distribution with <img src="https://render.githubusercontent.com/render/math?math=m"> and <img src="https://render.githubusercontent.com/render/math?math=n"> degrees of freedom respectively. 

The ratio of the two distributions

<img src="https://render.githubusercontent.com/render/math?math=F_{m\text{,}n} = \dfrac{\chi_m^2\text{/}m}{\chi_n^2\text{/}n}">

has an F-distribution with degrees of freedom <img src="https://render.githubusercontent.com/render/math?math=m"> and <img src="https://render.githubusercontent.com/render/math?math=n">. 

![](https://mathworld.wolfram.com/images/eps-svg/FDistribution_650.svg)

---
## Gamma Distribution
Exponential distribution describes the distribution of waiting times between successive changes, whereas Gamma distribution describes the distribution of waiting times until the 
<img src="https://render.githubusercontent.com/render/math?math=h\text{th}"> Possion event happens. Therefore,

<img src="https://render.githubusercontent.com/render/math?math=D(x) = 1 - P(X > x) = 1 - {\displaystyle \sum_{k=0}^{h-1}\dfrac{(\nu x)^ke^{-\nu x}}{k!}} = 1 - e^{-\nu x}{\displaystyle \sum_{k=0}^{h-1}\dfrac{(\nu x)^k}{k!}} = 1 - \dfrac{\Gamma(h,\nu x)}{\Gamma(h)}\ \ (x \geq 0)">

where 

<img src="https://render.githubusercontent.com/render/math?math=\Gamma(h) = (h-1)!"> 

is a complete gamma function, and 

<img src="https://render.githubusercontent.com/render/math?math=\Gamma(h,x) = {\displaystyle \int_{x}^{\infty}t^{h-1}e^{-t}dt = (n-1)!e^{-x}\sum_{k=0}^{h-1}\dfrac{x^k}{k!}}"> 

The corresponding probability function would be

<img src="/images/statistics/Gamma1.png" width="350"/>

Let <img src="https://render.githubusercontent.com/render/math?math=h=\alpha"> and <img src="https://render.githubusercontent.com/render/math?math=\nu=1\text{/}\theta">, then

<img src="https://render.githubusercontent.com/render/math?math=P(x) = \dfrac{x^{\alpha-1}e^{-x\text{/}\theta}}{\Gamma(\alpha)\theta^\alpha}">

which is the probability function for the gamma distribution.

![](https://mathworld.wolfram.com/images/eps-svg/GammaDistribution_651.svg)

---
## Beta Distribution
The Beta distribution is used as a prior distribution for binomial proportions in Bayesian analysis (see binomial distribution in [this](https://c-huang-tty.github.io/posts/2021/01/03/some-common-discrete-distributions/) post).

The probability function of Beta distribution is given by

<img src="https://render.githubusercontent.com/render/math?math=P(x) = \dfrac{(1-x)^{\beta-1}x^{\alpha-1}}{B(\alpha,\beta)} = \dfrac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}(1-x)^{\beta-1}x^{\alpha-1}">

and the cumulative distribution function is 

<img src="https://render.githubusercontent.com/render/math?math=D(x) = I(x%3Ba,b) = \dfrac{B(x%3Ba,b)}{B(a,b)}">

The image below gives plots for <img src="https://render.githubusercontent.com/render/math?math=\alpha=1"> and <img src="https://render.githubusercontent.com/render/math?math=\beta"> ranging from 0.25 and 3.00.

![](https://mathworld.wolfram.com/images/eps-svg/BetaDistribution_900.svg)

---
## Table of Contents
- [Probability vs Statistics](https://c-huang-tty.github.io/posts/2021/01/01/probability-and-statistics/)
- [Shakespear's New Poem](https://c-huang-tty.github.io/posts/2021/01/02/application-of-statistics/)
- [Some Common Discrete Distributions](https://c-huang-tty.github.io/posts/2021/01/03/some-common-discrete-distributions/)
- [Some Common Continuous Distributions](https://c-huang-tty.github.io/posts/2021/01/04/some-common-continuous-distributions/)
- [Statistical Quantities](https://c-huang-tty.github.io/posts/2021/01/05/statistical-quantities/)
- [Order Statistics](https://c-huang-tty.github.io/posts/2021/01/06/order-statistics/)
- [Multivariate Normal Distributions](https://c-huang-tty.github.io/posts/2021/01/07/multivariate-normal-distributions/)
- [Conditional Distributions and Expectation](https://c-huang-tty.github.io/posts/2021/01/08/conditonal-distributions-and-expectation/)
- [Problem Set [01] - Probabilities](https://c-huang-tty.github.io/posts/2021/01/21/problem-set-probabilities/)
- [Parameter Point Estimation](https://c-huang-tty.github.io/posts/2021/01/09/parameter-point-estimation/)
- [Evaluation of Point Estimation](https://c-huang-tty.github.io/posts/2021/01/10/evaluation-point-estimation/)
- [Parameter Interval Estimation](https://c-huang-tty.github.io/posts/2021/01/11/parameter-interval-estimation/)
- [Problem Set [02] - Parameter Estimation](https://c-huang-tty.github.io/posts/2021/01/22/problem-set-parameter-estimation/)
- [Parameter Hypothesis Test](https://c-huang-tty.github.io/posts/2021/01/12/parameter-hypothesis-test/)
- [t Test](https://c-huang-tty.github.io/posts/2021/01/13/t-test/)
- [Chi-Squared Test](https://c-huang-tty.github.io/posts/2021/01/14/chi-squared-test/)
- [Analysis of Variance](https://c-huang-tty.github.io/posts/2021/01/15/analysis-of-variance/)
- [Summary of Statistical Tests](https://c-huang-tty.github.io/posts/2021/01/16/summary-of-statistical-tests/)
- [Python [01] - Data Representation](https://c-huang-tty.github.io/posts/2021/01/17/statistics-python-data-representation/)
- [Python [02] - t Test & F Test](https://c-huang-tty.github.io/posts/2021/01/18/statistics-python-t-F-test/)
- [Python [03] - Chi-Squared Test](https://c-huang-tty.github.io/posts/2021/01/19/statistics-chi-squared-test/)
- [Experimental Design](https://c-huang-tty.github.io/posts/2021/01/20/experimental-design/)
- [Monte Carlo](https://c-huang-tty.github.io/posts/2021/01/23/monte-carlo/)
- [Variance Reducing Techniques](https://c-huang-tty.github.io/posts/2021/01/24/variance-reducing-techniques/)
- [From Uniform to General Distributions](https://c-huang-tty.github.io/posts/2021/01/25/from-uniform-to-general-distributions/)
- [Problem Set [03] - Monte Carlo](https://c-huang-tty.github.io/posts/2021/01/26/problem-set-monte-carlo/)
- [Unitary Regression Model](https://c-huang-tty.github.io/posts/2021/01/27/unitary-regression-model/)
- [Multiple Regression Model](https://c-huang-tty.github.io/posts/2021/01/28/multiple-regression-model/)
- [Factor and Principle Component Analysis](https://c-huang-tty.github.io/posts/2021/01/29/factor-principle-component-analysis/)
- [Clustering Analysis](https://c-huang-tty.github.io/posts/2021/01/30/clustering-analysis/)
- [Summary](https://c-huang-tty.github.io/posts/2021/01/31/summary/)
