---
title: 'Statistics [09]: Parameter Point Estimation'
date: 2021-01-09
permalink: /posts/2021/01/09/parameter-point-estimation/
tags:
  - Statistics
---

Assume <img src="https://render.githubusercontent.com/render/math?math=X_1,X_2,...,X_n"> are samples from a population, __point estimation__ refers to constructing certain statistical quantities <img src="https://render.githubusercontent.com/render/math?math=\hat{\theta} = \theta(X_1,X_2,...,X_n)"> that can be used to estimate the distribution of the population. The method is not unique, the most commonly used methods are the method of moments and the method of maximum likelihood. 

---
## Method of Moments
The basic idea is to equate sample moments with theoretical moments, where the moments can be __raw moments__ or __central moments__ or variance.

### Example 1
Assume <img src="https://render.githubusercontent.com/render/math?math=X_1,X_2,...,X_n"> are samples from uniform distribution <img src="https://render.githubusercontent.com/render/math?math=X\sim U(-a,a)">, estimate <img src="https://render.githubusercontent.com/render/math?math=a"> using the method of moments.

__Solution 1__.

<img src="https://render.githubusercontent.com/render/math?math=E(X)=0,\ \ var(X) = \dfrac{a^2}{3} = s^2 \Rightarrow \hat{a} = \sqrt{3}s">

__Solution 2__.

<img src="https://render.githubusercontent.com/render/math?math=E(X)=0,\ \ E(X^2) = \dfrac{a^2}{3} = \dfrac{X_1^2 %2B X_2^2 %2B ... %2B X_n^2 }{n}">

<img src="https://render.githubusercontent.com/render/math?math=\hat{a} = \sqrt{3}\sqrt{\dfrac{X_1^2 %2B X_2^2 %2B ... %2B X_n^2 }{n}}">

### Example 2
Assume <img src="https://render.githubusercontent.com/render/math?math=X_1,X_2,...,X_m"> are samples from binomial distribution <img src="https://render.githubusercontent.com/render/math?math=X\sim b(n,p)">, estimate <img src="https://render.githubusercontent.com/render/math?math=n,p"> using the method of moments.

__Solution 1__.

<img src="https://render.githubusercontent.com/render/math?math=E(X)=np = \bar{x},\ \ var(X) = np(1-p) = s^2">

<img src="https://render.githubusercontent.com/render/math?math=\hat{p} = 1 - \dfrac{s^2}{\bar{x}},\ \ \hat{n} = \dfrac{\bar{x}^2}{\bar{x}-s^2}">

__Solution 2__.

<img src="https://render.githubusercontent.com/render/math?math=E(X)=np = \bar{x},\ \ E(X^2) = np(1-p) %2B n^2p^2 = \dfrac{X_1^2 %2B X_2^2 %2B ... %2B X_m^2 }{m} = \bar{x}(1-p) %2B \bar{x}^2">

<img src="https://render.githubusercontent.com/render/math?math=\hat{p} = 1 %2B \bar{x} - \dfrac{X_1^2 %2B X_2^2 %2B ... %2B X_m^2 }{m\bar{x}},\ \ \hat{n} = \dfrac{m\bar{x}^2}{m\bar{x} %2B m\bar{x}^2 - X_1^2 %2B X_2^2 %2B ... %2B X_m^2 }">

---
## Method of Maximum Likelihood
The abasic idea of maximum likelihood is to estimate the unknown parameters <img src="https://render.githubusercontent.com/render/math?math=\theta"> that would maximize the probability of getting the data we have observed. 

Assume we have a random sample <img src="https://render.githubusercontent.com/render/math?math=X_1,X_2,...,X_n">, each with a probability function <img src="https://render.githubusercontent.com/render/math?math=p(x_i%3B \theta)">. Then, the likelihood function can be expressed as 

<img src="https://render.githubusercontent.com/render/math?math=L(\theta%3B x_1,x_2,...,x_n) = {\displaystyle \prod_{k=1}^n p(x_k%3B \theta)}">

If <img src="https://render.githubusercontent.com/render/math?math=\hat{\theta} = \hat{\theta}(x_1,x_2,...,x_n)"> satisfies <img src="https://render.githubusercontent.com/render/math?math=L(\hat{\theta}) = {\displaystyle \max_{\theta\in\Theta}L(\theta)}">, then <img src="https://render.githubusercontent.com/render/math?math=\hat{\theta}"> is called __maximum likelihood estimation (MLE)__.

In practice, we often use the log form of the likelihood function, then it becomes

<img src="https://render.githubusercontent.com/render/math?math=\ln(L(\theta%3B x_1,x_2,...,x_n)) = {\displaystyle \sum_{k=1}^n \ln(p(x_k%3B \theta))}">

### Example 3
Assume <img src="https://render.githubusercontent.com/render/math?math=x_1,x_2,...,x_n"> are samples from exponential distribution <img src="https://render.githubusercontent.com/render/math?math=\Exp(\lambda)">, find <img src="https://render.githubusercontent.com/render/math?math=\lambda">.

__Solution__.

<img src="https://render.githubusercontent.com/render/math?math=L(\lambda%3B x_1,x_2,...,x_n) = {\displaystyle \prod_{k=1}^n \lambda\exp(-\lambda x_i) = \lambda^n\exp(-\lambda(x_1%2Bx_2%2B+...+x_n))}">.

<img src="https://render.githubusercontent.com/render/math?math=\ln(L(\lambda%3B x_1,x_2,...,x_n)) = {\displaystyle n\ln\lambda - \lambda(x_1%2Bx_2%2B+...+x_n)}">

<img src="https://render.githubusercontent.com/render/math?math=\max\ln L(\lambda)\Rightarrow {\displaystyle \dfrac{d\ln L(\lambda)}{d\lambda}= \dfrac{n}{\lambda} - (x_1%2Bx_2%2B+...+x_n) = 0}">

<img src="https://render.githubusercontent.com/render/math?math=\hat{\lambda} = \dfrac{1}{(x_1%2Bx_2%2B+...+x_n)/n} \Rightarrow \hat{\lambda} = \dfrac{1}{\bar{x}}">

### Example 4
Assume <img src="https://render.githubusercontent.com/render/math?math=x_1,x_2,...,x_n"> are samples from Poisson distribution <img src="https://render.githubusercontent.com/render/math?math=P(\lambda)">, find <img src="https://render.githubusercontent.com/render/math?math=\lambda">.

__Solution__.

<img src="https://render.githubusercontent.com/render/math?math=L(\lambda%3B x_1,x_2,...,x_n) = {\displaystyle \prod_{k=1}^n \dfrac{\lambda^{x_k}}{x_k!}e^{-\lambda} = \dfrac{1}{x_1!x_2!...x_n!}\lambda^{x_1%2Bx_2%2B+...+x_n}e^{-n\lambda}}">.

<img src="https://render.githubusercontent.com/render/math?math=\ln L(\lambda) = {\displaystyle C%2B (x_1%2Bx_2%2B+...+x_n)\ln\lambda - n\lambda}">

<img src="https://render.githubusercontent.com/render/math?math=\max\ln L(\lambda)\Rightarrow {\displaystyle \dfrac{d\ln L(\lambda)}{d\lambda}= \dfrac{1}{\lambda}(x_1%2Bx_2%2B+...+x_n) - n = 0}">

<img src="https://render.githubusercontent.com/render/math?math=\hat{\lambda} = \dfrac{x_1%2Bx_2%2B+...+x_n}{n}">

### Example 5
Assume <img src="https://render.githubusercontent.com/render/math?math=x_1,x_2,...,x_n"> are samples from normal distribution <img src="https://render.githubusercontent.com/render/math?math=N(\mu,\sigma^2)">, find <img src="https://render.githubusercontent.com/render/math?math=\mu, \sigma^2">.

__Solution__.

<img src="https://render.githubusercontent.com/render/math?math=L(\mu,\sigma^2%3B x_1,x_2,...,x_n) = {\displaystyle \prod_{k=1}^n \dfrac{1}{\sqrt{2\pi}\sigma}\exp{\left(-\dfrac{(x_k-\mu)^2}{2\sigma^2}\right)} = \left(\dfrac{1}{\sqrt{2\pi}\sigma}\right)^n\exp\left(-\dfrac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\right)}">.

<img src="https://render.githubusercontent.com/render/math?math=\ln L(\mu,\sigma^2) = {\displaystyle n\ln\left(\dfrac{1}{\sqrt{2\pi}}\right) - \dfrac{n}{2}\ln\sigma^2 - \dfrac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2}">

For <img src="https://render.githubusercontent.com/render/math?math=\mu">,

<img src="https://render.githubusercontent.com/render/math?math={\displaystyle \dfrac{\partial\ln L(\mu,\sigma^2)}{\partial\mu}= \dfrac{1}{\sigma^2}\sum_{i=1}^n(x_i-\mu) = 0 \Rightarrow \hat{\mu} = \dfrac{1}{n}\sum_{i=1}^n x_i = \bar{x}}">

For <img src="https://render.githubusercontent.com/render/math?math=\sigma^2">,

<img src="https://render.githubusercontent.com/render/math?math={\displaystyle \dfrac{\partial\ln L(\mu,\sigma^2)}{\partial\sigma^2}= -\dfrac{n}{2}\dfrac{1}{\sigma^2} %2B \dfrac{1}{2(\sigma^2)^2}\sum_{i=1}^n(x_i-\mu)^2 = 0 \Rightarrow \hat{\sigma}^2 = \dfrac{1}{n}\sum_{i=1}^n (x_i - \mu)^2 = \dfrac{1}{n}\sum_{i=1}^n (x_i - \bar{x})^2}">

---
## Table of Contents
- [Probability vs Statistics](https://c-huang-tty.github.io/posts/2021/01/01/probability-and-statistics/)
- [Shakespear's New Poem](https://c-huang-tty.github.io/posts/2021/01/02/application-of-statistics/)
- [Some Common Discrete Distributions](https://c-huang-tty.github.io/posts/2021/01/03/some-common-discrete-distributions/)
- [Some Common Continuous Distributions](https://c-huang-tty.github.io/posts/2021/01/04/some-common-continuous-distributions/)
- [Statistical Quantities](https://c-huang-tty.github.io/posts/2021/01/05/statistical-quantities/)
- [Order Statistics](https://c-huang-tty.github.io/posts/2021/01/06/order-statistics/)
- [Multivariate Normal Distributions](https://c-huang-tty.github.io/posts/2021/01/07/multivariate-normal-distributions/)
- [Conditional Distributions and Expectation](https://c-huang-tty.github.io/posts/2021/01/08/conditonal-distributions-and-expectation/)
- [Problem Set [01] - Probabilities](https://c-huang-tty.github.io/posts/2021/01/21/problem-set-probabilities/)
- [Parameter Point Estimation](https://c-huang-tty.github.io/posts/2021/01/09/parameter-point-estimation/)
- [Evaluation of Point Estimation](https://c-huang-tty.github.io/posts/2021/01/10/evaluation-point-estimation/)
- [Parameter Interval Estimation](https://c-huang-tty.github.io/posts/2021/01/11/parameter-interval-estimation/)
- [Problem Set [02] - Parameter Estimation](https://c-huang-tty.github.io/posts/2021/01/22/problem-set-parameter-estimation/)
- [Parameter Hypothesis Test](https://c-huang-tty.github.io/posts/2021/01/12/parameter-hypothesis-test/)
- [t Test](https://c-huang-tty.github.io/posts/2021/01/13/t-test/)
- [Chi-Squared Test](https://c-huang-tty.github.io/posts/2021/01/14/chi-squared-test/)
- [Analysis of Variance](https://c-huang-tty.github.io/posts/2021/01/15/analysis-of-variance/)
- [Summary of Statistical Tests](https://c-huang-tty.github.io/posts/2021/01/16/summary-of-statistical-tests/)
- [Python [01] - Data Representation](https://c-huang-tty.github.io/posts/2021/01/17/statistics-python-data-representation/)
- [Python [02] - t Test & F Test](https://c-huang-tty.github.io/posts/2021/01/18/statistics-python-t-F-test/)
- [Python [03] - Chi-Squared Test](https://c-huang-tty.github.io/posts/2021/01/19/statistics-chi-squared-test/)
- [Experimental Design](https://c-huang-tty.github.io/posts/2021/01/20/experimental-design/)
- [Monte Carlo](https://c-huang-tty.github.io/posts/2021/01/23/monte-carlo/)
- [Variance Reducing Techniques](https://c-huang-tty.github.io/posts/2021/01/24/variance-reducing-techniques/)
- [From Uniform to General Distributions](https://c-huang-tty.github.io/posts/2021/01/25/from-uniform-to-general-distributions/)
- [Problem Set [03] - Monte Carlo](https://c-huang-tty.github.io/posts/2021/01/26/problem-set-monte-carlo/)
- [Unitary Regression Model](https://c-huang-tty.github.io/posts/2021/01/27/unitary-regression-model/)
- [Multiple Regression Model](https://c-huang-tty.github.io/posts/2021/01/28/multiple-regression-model/)
- [Factor and Principle Component Analysis](https://c-huang-tty.github.io/posts/2021/01/29/factor-principle-component-analysis/)
- [Clustering Analysis](https://c-huang-tty.github.io/posts/2021/01/30/clustering-analysis/)
- [Summary](https://c-huang-tty.github.io/posts/2021/01/31/summary/)
